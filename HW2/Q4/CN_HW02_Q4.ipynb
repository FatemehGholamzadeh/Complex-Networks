{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CN_HW02_Q4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlbLnHdBoXnJ",
        "outputId": "f297eeb3-e75d-480a-9535-c9b67becd894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 37 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 46.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=5635cf24b87997c9109b7b6f8a92bfe13f4c9a02e51c0e20123874849b096d0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import re\n",
        "import sys\n",
        "from operator import add\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import os"
      ],
      "metadata": {
        "id": "MrdiTrSuoQU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeContribs(rank, urls):\n",
        "    \"\"\"Calculates URL contributions to the rank of other URLs.\"\"\"\n",
        "    for url in urls:\n",
        "        yield (url, rank)\n",
        "\n",
        "\n",
        "def parseNeighbors(urls):\n",
        "    \"\"\"Parses a urls pair string into urls pair.\"\"\"\n",
        "    parts = re.split(r'\\s+', urls)\n",
        "    return parts[0], parts[1]\n",
        "\n",
        "def parseNeighbors_trans(urls):\n",
        "    \"\"\"Parses a urls pair string into urls pair.\"\"\"\n",
        "    parts = re.split(r'\\s+', urls)\n",
        "    return parts[1], parts[0]\n",
        "\n",
        "def node_cmp(x, y):\n",
        "    if int(x[0]) < int(y[0]):\n",
        "        return -1\n",
        "    return 1\n",
        "\n",
        "def my_cmp(x):\n",
        "  return int(x[0])"
      ],
      "metadata": {
        "id": "b3UoBES6oba0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3mf4gP0oCZe"
      },
      "outputs": [],
      "source": [
        "input_file =  '/content/drive/MyDrive/Complex_Networks/HW02/Wiki-Vote.txt'\n",
        "iterations = 5 \n",
        "outout_dir =\"output\"\n",
        "try:\n",
        "    os.makedirs(outout_dir)\n",
        "except OSError:\n",
        "    if not os.path.isdir(outout_dir):\n",
        "        raise\n",
        "\n",
        "# Initialize the spark context.\n",
        "spark = SparkSession\\\n",
        "    .builder\\\n",
        "    .appName(\"PythonPageRank\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "lines = spark.read.text(input_file).rdd.map(lambda r: r[0])\n",
        "\n",
        "\n",
        "# Loads all URLs from input file and initialize their neighbors.\n",
        "all_urls = lines.map(lambda urls: parseNeighbors(urls)).distinct()\n",
        "links = all_urls.groupByKey().cache()\n",
        "links_transpose = lines.map(lambda urls: parseNeighbors_trans(urls)).distinct().groupByKey().cache()\n",
        "result_links = links.collect()\n",
        "result_transition = links_transpose.collect()\n",
        "hubs = links.map(lambda url_neighbors: (url_neighbors[0], 1.0))\n",
        "\n",
        "authority = None\n",
        "# Calculates and updates URL ranks continuously using PageRank algorithm.\n",
        "for iteration in range(iterations):\n",
        "    # Calculates URL contributions to the rank of other URLs.\n",
        "    # calculate authority\n",
        "    authority = links.join(hubs).flatMap(\n",
        "        lambda x: computeContribs(x[1][1], x[1][0])).reduceByKey(add)\n",
        "\n",
        "    max_value_a = authority.map(lambda x: x[1]).max()\n",
        "    authority = authority.mapValues(lambda x: x / max_value_a)\n",
        "\n",
        "    hubs = links_transpose.join(authority).flatMap(\n",
        "        lambda x: computeContribs(x[1][1], x[1][0])).reduceByKey(add)  \n",
        "    max_value_h = hubs.map(lambda x: x[1]).max()\n",
        "    hubs = hubs.mapValues(lambda x: x / max_value_h)\n",
        "\n",
        "# Collects all URL ranks and dump them to console.\n",
        "result_hubs = sorted(hubs.collect(), key=my_cmp)\n",
        "result_hubs = hubs.collect()\n",
        "\n",
        "text_file = open(outout_dir + \"/hub.txt\", \"w\")\n",
        "for _ in result_hubs:\n",
        "    text_file.write(str(_[0]) + \",%.5f\" % _[1] + \"\\n\")\n",
        "text_file.close()\n",
        "\n",
        "# result_authority = sorted(authority.collect(),  key=my_cmp)\n",
        "result_authority = authority.collect()\n",
        "\n",
        "text_file = open(outout_dir + \"/authority.txt\", \"w\")\n",
        "for _ in result_authority:\n",
        "    text_file.write(str( _[0]) + \",%.5f\" % _[1] + \"\\n\")\n",
        "text_file.close()\n",
        "\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sort Nodes based on authority Score**"
      ],
      "metadata": {
        "id": "1DZhwrhJAJbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to sort hte list by second item of tuple\n",
        "def Sort_Tuple(tup):  \n",
        "    # reverse = None (Sorts in Ascending order) \n",
        "    # key is set to sort using second element of \n",
        "    # sublist lambda has been used \n",
        "    tup.sort(key = lambda x: x[1],reverse=True) \n",
        "    return tup "
      ],
      "metadata": {
        "id": "tw8-SLQ9Ccqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for node in (Sort_Tuple(result_authority)[:10]) :\n",
        "  print(node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNusRCheCe6H",
        "outputId": "da66087c-0f47-4e36-8b6c-7221da11dd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('2398', 1.0)\n",
            "('4037', 0.9977207958136023)\n",
            "('3352', 0.9024990712420015)\n",
            "('1549', 0.8933904532987473)\n",
            "('762', 0.8752334923138549)\n",
            "('1297', 0.8736172836899779)\n",
            "('3089', 0.8734033014392443)\n",
            "('2565', 0.8620015229598714)\n",
            "('15', 0.8536687098722228)\n",
            "('2625', 0.8530062804275313)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sort Nodes based on hub Score**"
      ],
      "metadata": {
        "id": "dHNN2PMzAXHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for node in (Sort_Tuple(result_hubs)[:10]) :\n",
        "  print(node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73w6Sb2iBteq",
        "outputId": "b3051c82-fc8c-437b-91b2-ad34d54c6f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('2565', 1.0)\n",
            "('766', 0.9539738367956294)\n",
            "('2688', 0.8109012307736835)\n",
            "('457', 0.8083998263718667)\n",
            "('1166', 0.7572151832677456)\n",
            "('1549', 0.7208933608812452)\n",
            "('11', 0.6205408521474032)\n",
            "('1151', 0.5761852013414268)\n",
            "('1374', 0.5628874083453793)\n",
            "('1133', 0.493479413970747)\n"
          ]
        }
      ]
    }
  ]
}